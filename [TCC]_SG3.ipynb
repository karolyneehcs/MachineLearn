{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karolyneehcs/MachineLearn/blob/master/%5BTCC%5D_SG3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV_ylWt7YjoY"
      },
      "source": [
        "# StyleGAN3\n",
        "\n",
        "By [Derrick Schultz](https://twitter.com/dvsch), with contributions from [crimeacs](https://twitter.com/EarthML1)\n",
        "\n",
        "Just starting this...expect more updates soon.\n",
        "\n",
        "If you find this helpful, please consider backing me on [Patreon](https://www.patreon.com/bustbright) or becoming a [YouTube channel member](https://www.youtube.com/channel/UCaZuPdmZ380SFUMKHVsv_AA/join)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs28QcYEwPM_"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bdgviQQO8WJ",
        "outputId": "8d75e294-ef7c-4cf2-b97a-b037ea0c41b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: A100-SXM4-40GB (UUID: GPU-43224d89-6ee1-70b1-cd8e-eb1d69fa24d5)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL1ERDs1PKJy",
        "outputId": "00ac7852-c6cf-4918-8d52-1fcd4fab3a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfOWvhrkcJzS",
        "outputId": "d34a0dd5-1240-4b1a-b38a-930d3b298f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: jax 0.3.21\n",
            "Uninstalling jax-0.3.21:\n",
            "  Successfully uninstalled jax-0.3.21\n",
            "Found existing installation: jaxlib 0.3.20+cuda11.cudnn805\n",
            "Uninstalling jaxlib-0.3.20+cuda11.cudnn805:\n",
            "  Successfully uninstalled jaxlib-0.3.20+cuda11.cudnn805\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jax[cuda11_cudnn805]==0.3.10\n",
            "  Downloading jax-0.3.10.tar.gz (939 kB)\n",
            "\u001b[K     |████████████████████████████████| 939 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.21.6)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.7.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (4.1.1)\n",
            "Collecting jaxlib==0.3.10+cuda11.cudnn805\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.10%2Bcuda11.cudnn805-cp37-none-manylinux2014_x86_64.whl (175.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 175.7 MB 7.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.3.10+cuda11.cudnn805->jax[cuda11_cudnn805]==0.3.10) (1.12)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.3.10-py3-none-any.whl size=1088066 sha256=a8d14052a1c004bc1e1d16fdcf9c4f128be68321a75e496d682343869b767975\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/05/23/36730377cd7311156f1e5eb5e7c683d5cdac1654658c095cc5\n",
            "Successfully built jax\n",
            "Installing collected packages: jaxlib, jax\n",
            "Successfully installed jax-0.3.10 jaxlib-0.3.10+cuda11.cudnn805\n",
            "Found existing installation: torch 1.12.1+cu113\n",
            "Uninstalling torch-1.12.1+cu113:\n",
            "  Successfully uninstalled torch-1.12.1+cu113\n",
            "Found existing installation: torchvision 0.13.1+cu113\n",
            "Uninstalling torchvision-0.13.1+cu113:\n",
            "  Successfully uninstalled torchvision-0.13.1+cu113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.2 MB/s eta 0:16:47tcmalloc: large alloc 1147494400 bytes == 0x399a8000 @  0x7fcf043de615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:27tcmalloc: large alloc 1434370048 bytes == 0x7dffe000 @  0x7fcf043de615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:45tcmalloc: large alloc 1792966656 bytes == 0x2e30000 @  0x7fcf043de615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:05:02tcmalloc: large alloc 2241208320 bytes == 0x6dc18000 @  0x7fcf043de615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf357a000 @  0x7fcf043dd1e7 0x4b2150 0x4b21dc 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x1e14f8000 @  0x7fcf043de615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x4ba899 0x4d29f9\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 6.6 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
            "Installing collected packages: torch, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu111 torchvision-0.10.0+cu111\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting ftfy==6.1.1\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting ninja==1.10.2\n",
            "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 913 kB/s \n",
            "\u001b[?25hCollecting opensimplex\n",
            "  Downloading opensimplex-0.4.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm==0.4.12) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.4.12) (0.10.0+cu111)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy==6.1.1) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm==0.4.12) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from opensimplex) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.12) (7.1.2)\n",
            "Installing collected packages: timm, opensimplex, ninja, imageio-ffmpeg, ftfy\n",
            "Successfully installed ftfy-6.1.1 imageio-ffmpeg-0.4.7 ninja-1.10.2 opensimplex-0.4.2 timm-0.4.12\n"
          ]
        }
      ],
      "source": [
        "#Uninstall new JAX\n",
        "!pip uninstall jax jaxlib -y\n",
        "#GPU frontend\n",
        "!pip install \"jax[cuda11_cudnn805]==0.3.10\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "#CPU frontend\n",
        "#!pip install jax[cpu]==0.3.10\n",
        "#Downgrade Pytorch\n",
        "!pip uninstall torch torchvision -y\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install timm==0.4.12 ftfy==6.1.1 ninja==1.10.2 imageio-ffmpeg opensimplex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ04kX_gPBIz",
        "outputId": "86cfa3e3-3276-4241-93d3-0ba902e19e44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/colab-sg3\n",
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 209, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 209 (delta 0), reused 2 (delta 0), pack-reused 206\u001b[K\n",
            "Receiving objects: 100% (209/209), 4.23 MiB | 16.54 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "/content/drive/MyDrive/colab-sg3/stylegan3\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/gdown\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gdown/cli.py\", line 166, in main\n",
            "    resume=args.continue_,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gdown/download.py\", line 202, in download\n",
            "    for file in os.listdir(osp.dirname(output) or \".\"):\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/pretrained'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opensimplex in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from opensimplex) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/colab-sg3\"):\n",
        "    %cd \"/content/drive/MyDrive/colab-sg3/stylegan3/\"\n",
        "elif os.path.isdir(\"/content/drive/\"):\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir colab-sg3\n",
        "    %cd colab-sg3\n",
        "    !git clone https://github.com/dvschultz/stylegan3\n",
        "    %cd stylegan3\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O /content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/pretrained/wikiart.pkl\n",
        "else:\n",
        "    !git clone https://github.com/dvschultz/stylegan3\n",
        "    %cd stylegan3\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    %cd pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU\n",
        "    %cd ../\n",
        "\n",
        "!pip install opensimplex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emTj0bXqeyBH"
      },
      "source": [
        "This cell will update to the latest repo. Git and Drive/Colab don’t play as nicely as I’d like so 🤞. The other option is to delete your folder in Drive (after saving out `/results` and `/datasets`!) and running the script above to replace the entire folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tgIuCLRehuP",
        "outputId": "e77e57a3-cc1c-4d35-bb20-e880007c5ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch'\n",
            "/content/drive/MyDrive/colab-sg3/stylegan3\n",
            "Already up to date.\n",
            "No local changes to save\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n",
        "!git config --global user.name \"test\"\n",
        "!git config --global user.email \"test@test.com\"\n",
        "!git fetch origin\n",
        "!git pull\n",
        "!git stash\n",
        "!git checkout origin/main -- train.py gen_images.py gen_video.py README.md training/training_loop.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT42eC_tPx87"
      },
      "source": [
        "## Convert/Create Dataset\n",
        "Pass a folder of images (just .pngs? TK) to create a zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO7APWvfPbXS",
        "outputId": "6cc0790f-909b-4bed-e37c-b93e983af055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 36% 367/1028 [00:37<00:54, 12.04it/s]Error: Image 00000/img00000368.png attributes must be equal across all images of the dataset.  Got:\n",
            "  dataset width/cur image width: 1024/1092\n",
            "  dataset height/cur image height: 1024/1024\n",
            "  dataset channels/cur image channels: 3/3\n",
            " 36% 368/1028 [00:37<01:07,  9.76it/s]\n"
          ]
        }
      ],
      "source": [
        "!python dataset_tool.py --source=/content/drive/MyDrive/Dataset/Ghibli --dest=./datasets/ghibli-1024.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkruyuspXigs"
      },
      "source": [
        "## Training\n",
        "\n",
        "Before you start training, read [this](https://github.com/dvschultz/stylegan3/blob/main/docs/configs.md).\n",
        "\n",
        "Working Notes:\n",
        "- It appears that you must use an SG3 pre-trained model for transfer learning. I _think_ you also want to match config to the pretrained model (`t` with `t`, `r` with `r`).\n",
        "- For an `A100` I’ve found you can use a `--batch-gpu=8`. For other GPUs I recommend `--batch-gpu=4`.\n",
        "- I see `~205 sec/kimg` on A100s, and `~325 sec/kimg` on V100s (1024, `r` config). This seems slightly slower than what [NVIDIA reports.](https://github.com/dvschultz/stylegan3/blob/main/docs/configs.md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TODwnBpnZYAO",
        "outputId": "0400f613-a3c7-44d3-e652-56870dca49b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: train.py [OPTIONS]\n",
            "\n",
            "  Train a GAN using the techniques described in\n",
            "  the paper \"Alias-Free Generative Adversarial\n",
            "  Networks\".\n",
            "\n",
            "  Examples:\n",
            "\n",
            "  # Train StyleGAN3-T for AFHQv2 using 8 GPUs.\n",
            "  python train.py --outdir=~/training-runs --cfg=stylegan3-t --data=~/datasets/afhqv2-512x512.zip \\\n",
            "      --gpus=8 --batch=32 --gamma=8.2 --mirror=1\n",
            "\n",
            "  # Fine-tune StyleGAN3-R for MetFaces-U using 1 GPU, starting from the pre-trained FFHQ-U pickle.\n",
            "  python train.py --outdir=~/training-runs --cfg=stylegan3-r --data=~/datasets/metfacesu-1024x1024.zip \\\n",
            "      --gpus=8 --batch=32 --gamma=6.6 --mirror=1 --kimg=5000 --snap=5 \\\n",
            "      --resume=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl\n",
            "\n",
            "  # Train StyleGAN2 for FFHQ at 1024x1024 resolution using 8 GPUs.\n",
            "  python train.py --outdir=~/training-runs --cfg=stylegan2 --data=~/datasets/ffhq-1024x1024.zip \\\n",
            "      --gpus=8 --batch=32 --gamma=10 --mirror=1 --aug=noaug\n",
            "\n",
            "Options:\n",
            "  --outdir DIR                    Where to save\n",
            "                                  the results\n",
            "                                  [required]\n",
            "\n",
            "  --cfg [stylegan3-t|stylegan3-r|stylegan2]\n",
            "                                  Base\n",
            "                                  configuration\n",
            "                                  [required]\n",
            "\n",
            "  --data [ZIP|DIR]                Training data\n",
            "                                  [required]\n",
            "\n",
            "  --gpus INT                      Number of GPUs\n",
            "                                  to use\n",
            "                                  [required]\n",
            "\n",
            "  --batch INT                     Total batch size\n",
            "                                  [required]\n",
            "\n",
            "  --gamma FLOAT                   R1\n",
            "                                  regularization\n",
            "                                  weight\n",
            "                                  [required]\n",
            "\n",
            "  --cond BOOL                     Train\n",
            "                                  conditional\n",
            "                                  model  [default:\n",
            "                                  False]\n",
            "\n",
            "  --mirror BOOL                   Enable dataset\n",
            "                                  x-flips\n",
            "                                  [default: False]\n",
            "\n",
            "  --mirrory BOOL                  Enable dataset\n",
            "                                  y-flips\n",
            "                                  [default: False]\n",
            "\n",
            "  --aug [noaug|ada|fixed]         Augmentation\n",
            "                                  mode  [default:\n",
            "                                  ada]\n",
            "\n",
            "  --augpipe [b|bg|bgc]            Augmentation\n",
            "                                  pipeline\n",
            "                                  [default: bgc]\n",
            "\n",
            "  --resume [PATH|URL|\"latest\"]    Resume from\n",
            "                                  given network\n",
            "                                  pickle (PATH,\n",
            "                                  URL or \"latest\")\n",
            "\n",
            "  --freezed INT                   Freeze first\n",
            "                                  layers of D\n",
            "                                  [default: 0]\n",
            "\n",
            "  --initstrength FLOAT RANGE      Override ADA\n",
            "                                  strength at\n",
            "                                  start\n",
            "\n",
            "  --p FLOAT                       Probability for\n",
            "                                  --aug=fixed\n",
            "                                  [default: 0.2]\n",
            "\n",
            "  --target FLOAT                  Target value for\n",
            "                                  --aug=ada\n",
            "                                  [default: 0.6]\n",
            "\n",
            "  --batch-gpu INT                 Limit batch size\n",
            "                                  per GPU\n",
            "\n",
            "  --cbase INT                     Capacity\n",
            "                                  multiplier\n",
            "                                  [default: 32768]\n",
            "\n",
            "  --cmax INT                      Max. feature\n",
            "                                  maps  [default:\n",
            "                                  512]\n",
            "\n",
            "  --glr FLOAT                     G learning rate\n",
            "                                  [default:\n",
            "                                  varies]\n",
            "\n",
            "  --dlr FLOAT                     D learning rate\n",
            "                                  [default: 0.002]\n",
            "\n",
            "  --map-depth INT                 Mapping network\n",
            "                                  depth  [default:\n",
            "                                  varies]\n",
            "\n",
            "  --mbstd-group INT               Minibatch std\n",
            "                                  group size\n",
            "                                  [default: 4]\n",
            "\n",
            "  --desc STR                      String to\n",
            "                                  include in\n",
            "                                  result dir name\n",
            "\n",
            "  --metrics [NAME|A,B,C|none]     Quality metrics\n",
            "                                  [default:\n",
            "                                  fid50k_full]\n",
            "\n",
            "  --kimg KIMG                     Total training\n",
            "                                  duration\n",
            "                                  [default: 25000]\n",
            "\n",
            "  --tick KIMG                     How often to\n",
            "                                  print progress\n",
            "                                  [default: 4]\n",
            "\n",
            "  --snap TICKS                    How often to\n",
            "                                  save snapshots\n",
            "                                  [default: 50]\n",
            "\n",
            "  --seed INT                      Random seed\n",
            "                                  [default: 0]\n",
            "\n",
            "  --fp32 BOOL                     Disable mixed-\n",
            "                                  precision\n",
            "                                  [default: False]\n",
            "\n",
            "  --nobench BOOL                  Disable cuDNN\n",
            "                                  benchmarking\n",
            "                                  [default: False]\n",
            "\n",
            "  --workers INT                   DataLoader\n",
            "                                  worker processes\n",
            "                                  [default: 3]\n",
            "\n",
            "  -n, --dry-run                   Print training\n",
            "                                  options and exit\n",
            "\n",
            "  --help                          Show this\n",
            "                                  message and\n",
            "                                  exit.\n"
          ]
        }
      ],
      "source": [
        "!python train.py --help"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "yVf9ipXxUf_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sbpJOHnXn6X",
        "outputId": "27388538-830e-42c3-a162-6bf777fc3bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 10.0,\n",
            "    \"blur_init_sigma\": 0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/colab-sg3/stylegan3/datasets/ghibli-1024.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 368,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 1024,\n",
            "    \"yflip\": false,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 25000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 1,\n",
            "  \"network_snapshot_ticks\": 1,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"./results/00001-stylegan3-t-ghibli-1024-gpus1-batch32-gamma10\"\n",
            "}\n",
            "\n",
            "Output directory:    ./results/00001-stylegan3-t-ghibli-1024-gpus1-batch32-gamma10\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   25000 kimg\n",
            "Dataset path:        /content/drive/MyDrive/colab-sg3/stylegan3/datasets/ghibli-1024.zip\n",
            "Dataset size:        368 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  736\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [8, 512]             float32 \n",
            "mapping.fc1                   262656      -        [8, 512]             float32 \n",
            "mapping                       -           512      [8, 16, 512]         float32 \n",
            "synthesis.input.affine        2052        -        [8, 4]               float32 \n",
            "synthesis.input               262144      1545     [8, 512, 36, 36]     float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L0_36_512           2359808     25       [8, 512, 36, 36]     float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L1_36_512           2359808     25       [8, 512, 36, 36]     float32 \n",
            "synthesis.L2_52_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L2_52_512           2359808     37       [8, 512, 52, 52]     float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L3_52_512           2359808     25       [8, 512, 52, 52]     float32 \n",
            "synthesis.L4_84_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L4_84_512           2359808     37       [8, 512, 84, 84]     float32 \n",
            "synthesis.L5_148_512.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L5_148_512          2359808     37       [8, 512, 148, 148]   float16 \n",
            "synthesis.L6_148_512.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L6_148_512          2359808     25       [8, 512, 148, 148]   float16 \n",
            "synthesis.L7_276_323.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L7_276_323          1488707     37       [8, 323, 276, 276]   float16 \n",
            "synthesis.L8_276_203.affine   165699      -        [8, 323]             float32 \n",
            "synthesis.L8_276_203          590324      25       [8, 203, 276, 276]   float16 \n",
            "synthesis.L9_532_128.affine   104139      -        [8, 203]             float32 \n",
            "synthesis.L9_532_128          233984      37       [8, 128, 532, 532]   float16 \n",
            "synthesis.L10_1044_81.affine  65664       -        [8, 128]             float32 \n",
            "synthesis.L10_1044_81         93393       37       [8, 81, 1044, 1044]  float16 \n",
            "synthesis.L11_1044_51.affine  41553       -        [8, 81]              float32 \n",
            "synthesis.L11_1044_51         37230       25       [8, 51, 1044, 1044]  float16 \n",
            "synthesis.L12_1044_32.affine  26163       -        [8, 51]              float32 \n",
            "synthesis.L12_1044_32         14720       25       [8, 32, 1044, 1044]  float16 \n",
            "synthesis.L13_1024_32.affine  16416       -        [8, 32]              float32 \n",
            "synthesis.L13_1024_32         9248        25       [8, 32, 1024, 1024]  float16 \n",
            "synthesis.L14_1024_3.affine   16416       -        [8, 32]              float32 \n",
            "synthesis.L14_1024_3          99          1        [8, 3, 1024, 1024]   float16 \n",
            "synthesis                     -           -        [8, 3, 1024, 1024]   float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         22313167    2480     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b1024.fromrgb  128         16       [8, 32, 1024, 1024]  float16 \n",
            "b1024.skip     2048        16       [8, 64, 512, 512]    float16 \n",
            "b1024.conv0    9248        16       [8, 32, 1024, 1024]  float16 \n",
            "b1024.conv1    18496       16       [8, 64, 512, 512]    float16 \n",
            "b1024          -           16       [8, 64, 512, 512]    float16 \n",
            "b512.skip      8192        16       [8, 128, 256, 256]   float16 \n",
            "b512.conv0     36928       16       [8, 64, 512, 512]    float16 \n",
            "b512.conv1     73856       16       [8, 128, 256, 256]   float16 \n",
            "b512           -           16       [8, 128, 256, 256]   float16 \n",
            "b256.skip      32768       16       [8, 256, 128, 128]   float16 \n",
            "b256.conv0     147584      16       [8, 128, 256, 256]   float16 \n",
            "b256.conv1     295168      16       [8, 256, 128, 128]   float16 \n",
            "b256           -           16       [8, 256, 128, 128]   float16 \n",
            "b128.skip      131072      16       [8, 512, 64, 64]     float16 \n",
            "b128.conv0     590080      16       [8, 256, 128, 128]   float16 \n",
            "b128.conv1     1180160     16       [8, 512, 64, 64]     float16 \n",
            "b128           -           16       [8, 512, 64, 64]     float16 \n",
            "b64.skip       262144      16       [8, 512, 32, 32]     float32 \n",
            "b64.conv0      2359808     16       [8, 512, 64, 64]     float32 \n",
            "b64.conv1      2359808     16       [8, 512, 32, 32]     float32 \n",
            "b64            -           16       [8, 512, 32, 32]     float32 \n",
            "b32.skip       262144      16       [8, 512, 16, 16]     float32 \n",
            "b32.conv0      2359808     16       [8, 512, 32, 32]     float32 \n",
            "b32.conv1      2359808     16       [8, 512, 16, 16]     float32 \n",
            "b32            -           16       [8, 512, 16, 16]     float32 \n",
            "b16.skip       262144      16       [8, 512, 8, 8]       float32 \n",
            "b16.conv0      2359808     16       [8, 512, 16, 16]     float32 \n",
            "b16.conv1      2359808     16       [8, 512, 8, 8]       float32 \n",
            "b16            -           16       [8, 512, 8, 8]       float32 \n",
            "b8.skip        262144      16       [8, 512, 4, 4]       float32 \n",
            "b8.conv0       2359808     16       [8, 512, 8, 8]       float32 \n",
            "b8.conv1       2359808     16       [8, 512, 4, 4]       float32 \n",
            "b8             -           16       [8, 512, 4, 4]       float32 \n",
            "b4.mbstd       -           -        [8, 513, 4, 4]       float32 \n",
            "b4.conv        2364416     16       [8, 512, 4, 4]       float32 \n",
            "b4.fc          4194816     -        [8, 512]             float32 \n",
            "b4.out         513         -        [8, 1]               float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          29012513    544      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2022-10-18 13:45:05.471967: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 2m 29s       sec/tick 29.7    sec/kimg 928.01  maintenance 119.1  cpumem 7.98   gpumem 29.49  reserved 36.92  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "{\"results\": {\"fid50k_full\": 250.79458513500424}, \"metric\": \"fid50k_full\", \"total_time\": 1002.4335250854492, \"total_time_str\": \"16m 42s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1666101742.15236}\n",
            "tick 1     kimg 4.0      time 31m 31s      sec/tick 737.3   sec/kimg 184.31  maintenance 1005.1 cpumem 9.08   gpumem 14.75  reserved 23.52  augment 0.027\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 242.17588735315476}, \"metric\": \"fid50k_full\", \"total_time\": 989.3767158985138, \"total_time_str\": \"16m 29s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000004.pkl\", \"timestamp\": 1666103471.5497463}\n",
            "tick 2     kimg 8.0      time 1h 00m 23s   sec/tick 739.6   sec/kimg 184.91  maintenance 992.1  cpumem 9.41   gpumem 14.88  reserved 23.52  augment 0.051\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 212.41276922152832}, \"metric\": \"fid50k_full\", \"total_time\": 989.5191185474396, \"total_time_str\": \"16m 30s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000008.pkl\", \"timestamp\": 1666105203.4609349}\n",
            "tick 3     kimg 12.0     time 1h 29m 16s   sec/tick 740.4   sec/kimg 185.09  maintenance 992.3  cpumem 9.74   gpumem 15.29  reserved 23.52  augment 0.079\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 170.95356944380018}, \"metric\": \"fid50k_full\", \"total_time\": 992.8658003807068, \"total_time_str\": \"16m 33s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000012.pkl\", \"timestamp\": 1666106939.2042677}\n",
            "tick 4     kimg 16.0     time 1h 58m 12s   sec/tick 741.1   sec/kimg 185.29  maintenance 995.4  cpumem 9.74   gpumem 15.13  reserved 23.52  augment 0.109\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 155.97607583584437}, \"metric\": \"fid50k_full\", \"total_time\": 991.0033004283905, \"total_time_str\": \"16m 31s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000016.pkl\", \"timestamp\": 1666108673.9112291}\n",
            "tick 5     kimg 20.0     time 2h 27m 08s   sec/tick 741.9   sec/kimg 185.46  maintenance 993.6  cpumem 9.74   gpumem 15.23  reserved 23.52  augment 0.136\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 147.5582292731866}, \"metric\": \"fid50k_full\", \"total_time\": 993.677588224411, \"total_time_str\": \"16m 34s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000020.pkl\", \"timestamp\": 1666110412.0270722}\n",
            "tick 6     kimg 24.0     time 2h 56m 04s   sec/tick 740.7   sec/kimg 185.18  maintenance 996.3  cpumem 9.74   gpumem 15.33  reserved 23.52  augment 0.163\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 138.23780233787005}, \"metric\": \"fid50k_full\", \"total_time\": 991.0790238380432, \"total_time_str\": \"16m 31s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000024.pkl\", \"timestamp\": 1666112146.4145744}\n",
            "tick 7     kimg 28.0     time 3h 25m 01s   sec/tick 742.8   sec/kimg 185.70  maintenance 993.7  cpumem 9.74   gpumem 15.45  reserved 23.52  augment 0.193\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 135.79901382787148}, \"metric\": \"fid50k_full\", \"total_time\": 994.751378774643, \"total_time_str\": \"16m 35s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000028.pkl\", \"timestamp\": 1666113886.52879}\n",
            "tick 8     kimg 32.0     time 3h 54m 01s   sec/tick 743.2   sec/kimg 185.80  maintenance 997.3  cpumem 9.74   gpumem 15.47  reserved 23.52  augment 0.225\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 133.00024021747444}, \"metric\": \"fid50k_full\", \"total_time\": 991.2364535331726, \"total_time_str\": \"16m 31s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000032.pkl\", \"timestamp\": 1666115623.5533648}\n",
            "tick 9     kimg 36.0     time 4h 22m 59s   sec/tick 744.0   sec/kimg 185.99  maintenance 993.8  cpumem 9.75   gpumem 15.42  reserved 23.53  augment 0.255\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 129.6162143963681}, \"metric\": \"fid50k_full\", \"total_time\": 992.3709137439728, \"total_time_str\": \"16m 32s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000036.pkl\", \"timestamp\": 1666117362.4895995}\n"
          ]
        }
      ],
      "source": [
        "!python train.py --outdir=./results --cfg=stylegan3-t --data=/content/drive/MyDrive/colab-sg3/stylegan3/datasets/ghibli-1024.zip \\\n",
        "--gpus=1 --batch=32 --batch-gpu=8 --gamma=10.0 --mirror=1 --kimg=25000 --snap=1 \\\n",
        "--resume=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl\n",
        "\n",
        "# 12.29 (A100 * 2500 kimg * 1.05 = tempo estimado de treinamento )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YMK6ADrN1_O"
      },
      "source": [
        "## Image Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T_5FWyVOd5R"
      },
      "outputs": [],
      "source": [
        "!python gen_images.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1_9acWpQ-Sw"
      },
      "outputs": [],
      "source": [
        "!python gen_images.py --outdir=out --trunc=1 --seeds=2 \\\n",
        "    --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1go7uPzwN_O6"
      },
      "source": [
        "## Video Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfK24HUUOcgc"
      },
      "outputs": [],
      "source": [
        "!python gen_video.py --help\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfDwRHVFOBJU"
      },
      "outputs": [],
      "source": [
        "!python gen_video.py --output=/content/lerp.mp4 --trunc=1 --seeds=100-124 --grid=1x1 --w-frames=72 \\\n",
        "    --network=/content/drive/MyDrive/colab-sg3/stylegan3/results/00014-stylegan3-r-drawn-gems-1024-gpus1-batch32-gamma10/network-snapshot-000104.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHVJkWOwfMhE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}